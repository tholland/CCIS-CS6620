{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 4 - Assignment Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by including the functions to generate frequent itemsets (via the Apriori algorithm) and resulting association rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (c) 2016 Everaldo Aguiar & Reid Johnson\n",
    "#\n",
    "# Modified from:\n",
    "# Marcel Caraciolo (https://gist.github.com/marcelcaraciolo/1423287)\n",
    "#\n",
    "# Functions to compute and extract association rules from a given frequent itemset \n",
    "# generated by the Apriori algorithm.\n",
    "#\n",
    "# The Apriori algorithm is defined by Agrawal and Srikant in:\n",
    "# Fast algorithms for mining association rules\n",
    "# Proc. 20th int. conf. very large data bases, VLDB. Vol. 1215. 1994\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def load_dataset(filename):\n",
    "    '''Loads an example of market basket transactions from a provided csv file.\n",
    "\n",
    "    Returns: A list (database) of lists (transactions). Each element of a transaction is \n",
    "    an item.\n",
    "    '''\n",
    "\n",
    "    with open(filename,'r') as dest_f:\n",
    "        data_iter = csv.reader(dest_f, delimiter = ',', quotechar = '\"')\n",
    "        data = [data for data in data_iter]\n",
    "        data_array = np.asarray(data)\n",
    "        \n",
    "    return data_array\n",
    "\n",
    "def apriori(dataset, min_support=0.5, verbose=False):\n",
    "    \"\"\"Implements the Apriori algorithm.\n",
    "\n",
    "    The Apriori algorithm will iteratively generate new candidate \n",
    "    k-itemsets using the frequent (k-1)-itemsets found in the previous \n",
    "    iteration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list\n",
    "        The dataset (a list of transactions) from which to generate \n",
    "        candidate itemsets.\n",
    "\n",
    "    min_support : float\n",
    "        The minimum support threshold. Defaults to 0.5.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    F : list\n",
    "        The list of frequent itemsets.\n",
    "\n",
    "    support_data : dict\n",
    "        The support data for all candidate itemsets.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] R. Agrawal, R. Srikant, \"Fast Algorithms for Mining Association \n",
    "           Rules\", 1994.\n",
    "\n",
    "    \"\"\"\n",
    "    C1 = create_candidates(dataset)\n",
    "    D = list(map(set, dataset))\n",
    "    F1, support_data = support_prune(D, C1, min_support, verbose=False) # prune candidate 1-itemsets\n",
    "    F = [F1] # list of frequent itemsets; initialized to frequent 1-itemsets\n",
    "    k = 2 # the itemset cardinality\n",
    "    while (len(F[k - 2]) > 0):\n",
    "        Ck = apriori_gen(F[k-2], k) # generate candidate itemsets\n",
    "        Fk, supK = support_prune(D, Ck, min_support) # prune candidate itemsets\n",
    "        support_data.update(supK) # update the support counts to reflect pruning\n",
    "        F.append(Fk) # add the pruned candidate itemsets to the list of frequent itemsets\n",
    "        k += 1\n",
    "\n",
    "    if verbose:\n",
    "        # Print a list of all the frequent itemsets.\n",
    "        for kset in F:\n",
    "            for item in kset:\n",
    "                print(\"\" \\\n",
    "                    + \"{\" \\\n",
    "                    + \"\".join(str(i) + \", \" for i in iter(item)).rstrip(', ') \\\n",
    "                    + \"}\" \\\n",
    "                    + \":  sup = \" + str(round(support_data[item], 3)))\n",
    "\n",
    "    return F, support_data\n",
    "\n",
    "def create_candidates(dataset, verbose=False):\n",
    "    \"\"\"Creates a list of candidate 1-itemsets from a list of transactions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list\n",
    "        The dataset (a list of transactions) from which to generate candidate \n",
    "        itemsets.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The list of candidate itemsets (c1) passed as a frozenset (a set that is \n",
    "    immutable and hashable).\n",
    "    \"\"\"\n",
    "    c1 = [] # list of all items in the database of transactions\n",
    "    for transaction in dataset:\n",
    "        for item in transaction:\n",
    "            if not [item] in c1:\n",
    "                c1.append([item])\n",
    "    c1.sort()\n",
    "\n",
    "    if verbose:\n",
    "        # Print a list of all the candidate items.\n",
    "        print(\"\" \\\n",
    "            + \"{\" \\\n",
    "            + \"\".join(str(i[0]) + \", \" for i in iter(c1)).rstrip(', ') \\\n",
    "            + \"}\")\n",
    "\n",
    "    # Map c1 to a frozenset because it will be the key of a dictionary.\n",
    "    return list(map(frozenset, c1))\n",
    "\n",
    "def support_prune(dataset, candidates, min_support, verbose=False):\n",
    "    \"\"\"Returns all candidate itemsets that meet a minimum support threshold.\n",
    "\n",
    "    By the apriori principle, if an itemset is frequent, then all of its \n",
    "    subsets must also be frequent. As a result, we can perform support-based \n",
    "    pruning to systematically control the exponential growth of candidate \n",
    "    itemsets. Thus, itemsets that do not meet the minimum support level are \n",
    "    pruned from the input list of itemsets (dataset).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list\n",
    "        The dataset (a list of transactions) from which to generate candidate \n",
    "        itemsets.\n",
    "\n",
    "    candidates : frozenset\n",
    "        The list of candidate itemsets.\n",
    "\n",
    "    min_support : float\n",
    "        The minimum support threshold.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    retlist : list\n",
    "        The list of frequent itemsets.\n",
    "\n",
    "    support_data : dict\n",
    "        The support data for all candidate itemsets.\n",
    "    \"\"\"\n",
    "    sscnt = {} # set for support counts\n",
    "    for tid in dataset:\n",
    "        for can in candidates:\n",
    "            if can.issubset(tid):\n",
    "                sscnt.setdefault(can, 0)\n",
    "                sscnt[can] += 1\n",
    "\n",
    "    num_items = float(len(dataset)) # total number of transactions in the dataset\n",
    "    retlist = [] # array for unpruned itemsets\n",
    "    support_data = {} # set for support data for corresponding itemsets\n",
    "    for key in sscnt:\n",
    "        # Calculate the support of itemset key.\n",
    "        support = sscnt[key] / num_items\n",
    "        if support >= min_support:\n",
    "            retlist.insert(0, key)\n",
    "        support_data[key] = support\n",
    "\n",
    "    # Print a list of the pruned itemsets.\n",
    "    if verbose:\n",
    "        for kset in retlist:\n",
    "            for item in kset:\n",
    "                print(\"{\" + str(item) + \"}\")\n",
    "        print(\"\")\n",
    "        for key in sscnt:\n",
    "            print(\"\" \\\n",
    "                + \"{\" \\\n",
    "                + \"\".join([str(i) + \", \" for i in iter(key)]).rstrip(', ') \\\n",
    "                + \"}\" \\\n",
    "                + \":  sup = \" + str(support_data[key]))\n",
    "\n",
    "    return retlist, support_data\n",
    "\n",
    "def apriori_gen(freq_sets, k):\n",
    "    \"\"\"Generates candidate itemsets (via the F_k-1 x F_k-1 method).\n",
    "\n",
    "    This operation generates new candidate k-itemsets based on the frequent \n",
    "    (k-1)-itemsets found in the previous iteration. The candidate generation \n",
    "    procedure merges a pair of frequent (k-1)-itemsets only if their first k-2 \n",
    "    items are identical.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_sets : list\n",
    "        The list of frequent (k-1)-itemsets.\n",
    "\n",
    "    k : integer\n",
    "        The cardinality of the current itemsets being evaluated.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    retlist : list\n",
    "        The list of merged frequent itemsets.\n",
    "    \"\"\"\n",
    "    retList = [] # list of merged frequent itemsets\n",
    "    lenLk = len(freq_sets) # number of frequent itemsets\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1, lenLk):\n",
    "            a=list(freq_sets[i])\n",
    "            b=list(freq_sets[j])\n",
    "            a.sort()\n",
    "            b.sort()\n",
    "            F1 = a[:k-2] # first k-2 items of freq_sets[i]\n",
    "            F2 = b[:k-2] # first k-2 items of freq_sets[j]\n",
    "\n",
    "            if F1 == F2: # if the first k-2 items are identical\n",
    "                # Merge the frequent itemsets.\n",
    "                retList.append(freq_sets[i] | freq_sets[j])\n",
    "\n",
    "    return retList\n",
    "\n",
    "def rules_from_conseq(freq_set, H, support_data, rules, min_confidence=0.5, verbose=False):\n",
    "    \"\"\"Generates a set of candidate rules.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_set : frozenset\n",
    "        The complete list of frequent itemsets.\n",
    "\n",
    "    H : list\n",
    "        A list of frequent itemsets (of a particular length).\n",
    "\n",
    "    support_data : dict\n",
    "        The support data for all candidate itemsets.\n",
    "\n",
    "    rules : list\n",
    "        A potentially incomplete set of candidate rules above the minimum \n",
    "        confidence threshold.\n",
    "\n",
    "    min_confidence : float\n",
    "        The minimum confidence threshold. Defaults to 0.5.\n",
    "    \"\"\"\n",
    "    m = len(H[0])\n",
    "    if m == 1:\n",
    "        Hmp1 = calc_confidence(freq_set, H, support_data, rules, min_confidence, verbose)\n",
    "    if (len(freq_set) > (m+1)):\n",
    "        Hmp1 = apriori_gen(H, m+1) # generate candidate itemsets\n",
    "        Hmp1 = calc_confidence(freq_set, Hmp1, support_data, rules, min_confidence, verbose)\n",
    "        if len(Hmp1) > 1:\n",
    "            # If there are candidate rules above the minimum confidence \n",
    "            # threshold, recurse on the list of these candidate rules.\n",
    "            rules_from_conseq(freq_set, Hmp1, support_data, rules, min_confidence, verbose)\n",
    "\n",
    "def calc_confidence(freq_set, H, support_data, rules, min_confidence=0.5, verbose=False):\n",
    "    \"\"\"Evaluates the generated rules.\n",
    "\n",
    "    One measurement for quantifying the goodness of association rules is \n",
    "    confidence. The confidence for a rule 'P implies H' (P -> H) is defined as \n",
    "    the support for P and H divided by the support for P \n",
    "    (support (P|H) / support(P)), where the | symbol denotes the set union \n",
    "    (thus P|H means all the items in set P or in set H).\n",
    "\n",
    "    To calculate the confidence, we iterate through the frequent itemsets and \n",
    "    associated support data. For each frequent itemset, we divide the support \n",
    "    of the itemset by the support of the antecedent (left-hand-side of the \n",
    "    rule).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq_set : frozenset\n",
    "        The complete list of frequent itemsets.\n",
    "\n",
    "    H : list\n",
    "        A list of frequent itemsets (of a particular length).\n",
    "\n",
    "    min_support : float\n",
    "        The minimum support threshold.\n",
    "\n",
    "    rules : list\n",
    "        A potentially incomplete set of candidate rules above the minimum \n",
    "        confidence threshold.\n",
    "\n",
    "    min_confidence : float\n",
    "        The minimum confidence threshold. Defaults to 0.5.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pruned_H : list\n",
    "        The list of candidate rules above the minimum confidence threshold.\n",
    "    \"\"\"\n",
    "    pruned_H = [] # list of candidate rules above the minimum confidence threshold\n",
    "    for conseq in H: # iterate over the frequent itemsets\n",
    "        conf = support_data[freq_set] / support_data[freq_set - conseq]\n",
    "        if conf >= min_confidence:\n",
    "            rules.append((freq_set - conseq, conseq, conf))\n",
    "            pruned_H.append(conseq)\n",
    "\n",
    "            if verbose:\n",
    "                print(\"\" \\\n",
    "                    + \"{\" \\\n",
    "                    + \"\".join([str(i) + \", \" for i in iter(freq_set-conseq)]).rstrip(', ') \\\n",
    "                    + \"}\" \\\n",
    "                    + \" ---> \" \\\n",
    "                    + \"{\" \\\n",
    "                    + \"\".join([str(i) + \", \" for i in iter(conseq)]).rstrip(', ') \\\n",
    "                    + \"}\" \\\n",
    "                    + \":  conf = \" + str(round(conf, 3)) \\\n",
    "                    + \", sup = \" + str(round(support_data[freq_set], 3)))\n",
    "\n",
    "    return pruned_H\n",
    "\n",
    "def generate_rules(F, support_data, min_confidence=0.5, verbose=True):\n",
    "    \"\"\"Generates a set of candidate rules from a list of frequent itemsets.\n",
    "\n",
    "    For each frequent itemset, we calculate the confidence of using a\n",
    "    particular item as the rule consequent (right-hand-side of the rule). By \n",
    "    testing and merging the remaining rules, we recursively create a list of \n",
    "    pruned rules.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    F : list\n",
    "        A list of frequent itemsets.\n",
    "\n",
    "    support_data : dict\n",
    "        The corresponding support data for the frequent itemsets (L).\n",
    "\n",
    "    min_confidence : float\n",
    "        The minimum confidence threshold. Defaults to 0.5.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rules : list\n",
    "        The list of candidate rules above the minimum confidence threshold.\n",
    "    \"\"\"\n",
    "    rules = []\n",
    "    for i in range(1, len(F)):\n",
    "        for freq_set in F[i]:\n",
    "            H1 = [frozenset([itemset]) for itemset in freq_set]\n",
    "            if (i > 1):\n",
    "                rules_from_conseq(freq_set, H1, support_data, rules, min_confidence, verbose)\n",
    "            else:\n",
    "                calc_confidence(freq_set, H1, support_data, rules, min_confidence, verbose)\n",
    "\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To load our dataset of grocery transactions, use the command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset('grocery.csv')\n",
    "D = list(map(set, dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _dataset_ is now a ndarray containing each of the 9835 transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9835,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['citrus fruit', 'semi-finished bread', 'margarine', 'ready soups']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tropical fruit', 'yogurt', 'coffee']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _D_ Contains that dataset in a set format (which excludes duplicated items and sorts them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(D[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'citrus fruit', 'margarine', 'ready soups', 'semi-finished bread'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Complete the assignment below by making use of the provided funtions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You may use the notebook file attached with lesson 3 as a reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FPGrowth provided on the class site (which uses a couple of the functions from above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (c) 2014 Reid Johnson\n",
    "#\n",
    "# Modified from:\n",
    "# Eric Naeseth <eric@naeseth.com>\n",
    "# (https://github.com/enaeseth/python-fp-growth/blob/master/fp_growth.py)\n",
    "#\n",
    "# A Python implementation of the FP-growth algorithm.\n",
    "\n",
    "from collections import defaultdict, namedtuple\n",
    "#from itertools import imap\n",
    "\n",
    "__author__ = 'Eric Naeseth <eric@naeseth.com>'\n",
    "__copyright__ = 'Copyright Â© 2009 Eric Naeseth'\n",
    "__license__ = 'MIT License'\n",
    "\n",
    "def fpgrowth(dataset, min_support=0.5, include_support=True, verbose=False):\n",
    "    \"\"\"Implements the FP-growth algorithm.\n",
    "\n",
    "    The `dataset` parameter can be any iterable of iterables of items.\n",
    "    `min_support` should be an integer specifying the minimum number of\n",
    "    occurrences of an itemset for it to be accepted.\n",
    "\n",
    "    Each item must be hashable (i.e., it must be valid as a member of a\n",
    "    dictionary or a set).\n",
    "\n",
    "    If `include_support` is true, yield (itemset, support) pairs instead of\n",
    "    just the itemsets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list\n",
    "        The dataset (a list of transactions) from which to generate \n",
    "        candidate itemsets.\n",
    "\n",
    "    min_support : float\n",
    "        The minimum support threshold. Defaults to 0.5.\n",
    "\n",
    "    include_support : bool\n",
    "        Include support in output (default=False).\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] J. Han, J. Pei, Y. Yin, \"Mining Frequent Patterns without Candidate \n",
    "           Generation,\" 2000.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    F = []\n",
    "    support_data = {}\n",
    "    #for k,v in find_frequent_itemsets(dataset, min_support=0.6, include_support=True, verbose=verbose):\n",
    "    for k,v in find_frequent_itemsets(dataset, min_support=min_support, include_support=include_support, verbose=verbose):\n",
    "        F.append(frozenset(k))\n",
    "        support_data[frozenset(k)] = v\n",
    "\n",
    "    # Create one array with subarrays that hold all transactions of equal length.\n",
    "    def bucket_list(nested_list, sort=True):\n",
    "        bucket = defaultdict(list)\n",
    "        for sublist in nested_list:\n",
    "            bucket[len(sublist)].append(sublist)\n",
    "        return [v for k,v in sorted(bucket.items())] if sort else bucket.values()\n",
    "\n",
    "    F = bucket_list(F)\n",
    "    \n",
    "    return F, support_data\n",
    "\n",
    "def find_frequent_itemsets(dataset, min_support, include_support=False, verbose=False):\n",
    "    \"\"\"\n",
    "    Find frequent itemsets in the given transactions using FP-growth. This\n",
    "    function returns a generator instead of an eagerly-populated list of items.\n",
    "\n",
    "    The `dataset` parameter can be any iterable of iterables of items.\n",
    "    `min_support` should be an integer specifying the minimum number of\n",
    "    occurrences of an itemset for it to be accepted.\n",
    "\n",
    "    Each item must be hashable (i.e., it must be valid as a member of a\n",
    "    dictionary or a set).\n",
    "\n",
    "    If `include_support` is true, yield (itemset, support) pairs instead of\n",
    "    just the itemsets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list\n",
    "        The dataset (a list of transactions) from which to generate \n",
    "        candidate itemsets.\n",
    "\n",
    "    min_support : float\n",
    "        The minimum support threshold. Defaults to 0.5.\n",
    "\n",
    "    include_support : bool\n",
    "        Include support in output (default=False).\n",
    "\n",
    "    \"\"\"\n",
    "    items = defaultdict(lambda: 0) # mapping from items to their supports\n",
    "    processed_transactions = []\n",
    "\n",
    "    # Load the passed-in transactions and count the support that individual\n",
    "    # items have.\n",
    "    for transaction in dataset:\n",
    "        processed = []\n",
    "        for item in transaction:\n",
    "            items[item] += 1\n",
    "            processed.append(item)\n",
    "        processed_transactions.append(processed)\n",
    "\n",
    "    # Remove infrequent items from the item support dictionary.\n",
    "    #items = dict((item, support) for item, support in items.iteritems()\n",
    "    items = dict((item, support) for item, support in items.items()\n",
    "        if support >= min_support)\n",
    "\n",
    "    # Build our FP-tree. Before any transactions can be added to the tree, they\n",
    "    # must be stripped of infrequent items and their surviving items must be\n",
    "    # sorted in decreasing order of frequency.\n",
    "    def clean_transaction(transaction):\n",
    "        #transaction = filter(lambda v: v in items, transaction)\n",
    "        transaction = list(filter(lambda v: v in items, transaction))\n",
    "        transaction.sort(key=lambda v: items[v], reverse=True)\n",
    "        return transaction\n",
    "\n",
    "    master = FPTree()\n",
    "    #for transaction in imap(clean_transaction, processed_transactions):\n",
    "    #FIXME of is it list(map()) instead of map()\n",
    "    for transaction in map(clean_transaction, processed_transactions):\n",
    "        master.add(transaction)\n",
    "\n",
    "    support_data = {}\n",
    "    def find_with_suffix(tree, suffix):\n",
    "        for item, nodes in tree.items():\n",
    "            support = float(sum(n.count for n in nodes)) / len(dataset)\n",
    "            if support >= min_support and item not in suffix:\n",
    "                # New winner!\n",
    "                found_set = [item] + suffix\n",
    "                support_data[frozenset(found_set)] = support\n",
    "                yield (found_set, support) if include_support else found_set\n",
    "\n",
    "                # Build a conditional tree and recursively search for frequent\n",
    "                # itemsets within it.\n",
    "                cond_tree = conditional_tree_from_paths(tree.prefix_paths(item),\n",
    "                    min_support)\n",
    "                for s in find_with_suffix(cond_tree, found_set):\n",
    "                    yield s # pass along the good news to our caller\n",
    "\n",
    "    if verbose:\n",
    "        # Print a list of all the frequent itemsets.\n",
    "        for itemset, support in find_with_suffix(master, []):\n",
    "            print(\"\" \\\n",
    "                + \"{\" \\\n",
    "                + \"\".join(str(i) + \", \" for i in iter(itemset)).rstrip(', ') \\\n",
    "                + \"}\" \\\n",
    "                + \":  sup = \" + str(round(support_data[frozenset(itemset)], 3)))\n",
    "\n",
    "    # Search for frequent itemsets, and yield the results we find.\n",
    "    for itemset in find_with_suffix(master, []):\n",
    "        yield itemset\n",
    "\n",
    "class FPTree(object):\n",
    "    \"\"\"\n",
    "    An FP tree.\n",
    "\n",
    "    This object may only store transaction items that are hashable (i.e., all\n",
    "    items must be valid as dictionary keys or set members).\n",
    "    \"\"\"\n",
    "\n",
    "    Route = namedtuple('Route', 'head tail')\n",
    "\n",
    "    def __init__(self):\n",
    "        # The root node of the tree.\n",
    "        self._root = FPNode(self, None, None)\n",
    "\n",
    "        # A dictionary mapping items to the head and tail of a path of\n",
    "        # \"neighbors\" that will hit every node containing that item.\n",
    "        self._routes = {}\n",
    "\n",
    "    @property\n",
    "    def root(self):\n",
    "        \"\"\"The root node of the tree.\"\"\"\n",
    "        return self._root\n",
    "\n",
    "    def add(self, transaction):\n",
    "        \"\"\"\n",
    "        Adds a transaction to the tree.\n",
    "        \"\"\"\n",
    "\n",
    "        point = self._root\n",
    "\n",
    "        for item in transaction:\n",
    "            next_point = point.search(item)\n",
    "            if next_point:\n",
    "                # There is already a node in this tree for the current\n",
    "                # transaction item; reuse it.\n",
    "                next_point.increment()\n",
    "            else:\n",
    "                # Create a new point and add it as a child of the point we're\n",
    "                # currently looking at.\n",
    "                next_point = FPNode(self, item)\n",
    "                point.add(next_point)\n",
    "\n",
    "                # Update the route of nodes that contain this item to include\n",
    "                # our new node.\n",
    "                self._update_route(next_point)\n",
    "\n",
    "            point = next_point\n",
    "\n",
    "    def _update_route(self, point):\n",
    "        \"\"\"Add the given node to the route through all nodes for its item.\"\"\"\n",
    "        assert self is point.tree\n",
    "\n",
    "        try:\n",
    "            route = self._routes[point.item]\n",
    "            route[1].neighbor = point # route[1] is the tail\n",
    "            self._routes[point.item] = self.Route(route[0], point)\n",
    "        except KeyError:\n",
    "            # First node for this item; start a new route.\n",
    "            self._routes[point.item] = self.Route(point, point)\n",
    "\n",
    "    def items(self):\n",
    "        \"\"\"\n",
    "        Generate one 2-tuples for each item represented in the tree. The first\n",
    "        element of the tuple is the item itself, and the second element is a\n",
    "        generator that will yield the nodes in the tree that belong to the item.\n",
    "        \"\"\"\n",
    "        #FIXME for item in self._routes.iterkeys():\n",
    "        for item in self._routes.keys():\n",
    "            yield (item, self.nodes(item))\n",
    "\n",
    "            \n",
    "    def nodes(self, item):\n",
    "        \"\"\"\n",
    "        Generates the sequence of nodes that contain the given item.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            node = self._routes[item][0]\n",
    "        except KeyError:\n",
    "            return\n",
    "\n",
    "        while node:\n",
    "            yield node\n",
    "            node = node.neighbor\n",
    "\n",
    "    def prefix_paths(self, item):\n",
    "        \"\"\"Generates the prefix paths that end with the given item.\"\"\"\n",
    "\n",
    "        def collect_path(node):\n",
    "            path = []\n",
    "            while node and not node.root:\n",
    "                path.append(node)\n",
    "                node = node.parent\n",
    "            path.reverse()\n",
    "            return path\n",
    "\n",
    "        return (collect_path(node) for node in self.nodes(item))\n",
    "\n",
    "    def inspect(self):\n",
    "        print(\"Tree:\")\n",
    "        self.root.inspect(1)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Routes:\")\n",
    "        for item, nodes in self.items():\n",
    "            print(\"  %r\" % item)\n",
    "            for node in nodes:\n",
    "                print(\"    %r\" % node)\n",
    "\n",
    "    def _removed(self, node):\n",
    "        \"\"\"Called when `node` is removed from the tree; performs cleanup.\"\"\"\n",
    "\n",
    "        head, tail = self._routes[node.item]\n",
    "        if node is head:\n",
    "            if node is tail or not node.neighbor:\n",
    "                # It was the sole node.\n",
    "                del self._routes[node.item]\n",
    "            else:\n",
    "                self._routes[node.item] = self.Route(node.neighbor, tail)\n",
    "        else:\n",
    "            for n in self.nodes(node.item):\n",
    "                if n.neighbor is node:\n",
    "                    n.neighbor = node.neighbor # skip over\n",
    "                    if node is tail:\n",
    "                        self._routes[node.item] = self.Route(head, n)\n",
    "                    break\n",
    "\n",
    "def conditional_tree_from_paths(paths, min_support):\n",
    "    \"\"\"Builds a conditional FP-tree from the given prefix paths.\"\"\"\n",
    "    tree = FPTree()\n",
    "    condition_item = None\n",
    "    items = set()\n",
    "\n",
    "    # Import the nodes in the paths into the new tree. Only the counts of the\n",
    "    # leaf notes matter; the remaining counts will be reconstructed from the\n",
    "    # leaf counts.\n",
    "    for path in paths:\n",
    "        if condition_item is None:\n",
    "            condition_item = path[-1].item\n",
    "\n",
    "        point = tree.root\n",
    "        for node in path:\n",
    "            next_point = point.search(node.item)\n",
    "            if not next_point:\n",
    "                # Add a new node to the tree.\n",
    "                items.add(node.item)\n",
    "                count = node.count if node.item == condition_item else 0\n",
    "                next_point = FPNode(tree, node.item, count)\n",
    "                point.add(next_point)\n",
    "                tree._update_route(next_point)\n",
    "            point = next_point\n",
    "\n",
    "    assert condition_item is not None\n",
    "\n",
    "    # Calculate the counts of the non-leaf nodes.\n",
    "    for path in tree.prefix_paths(condition_item):\n",
    "        count = path[-1].count\n",
    "        for node in reversed(path[:-1]):\n",
    "            node._count += count\n",
    "\n",
    "    # Eliminate the nodes for any items that are no longer frequent.\n",
    "    for item in items:\n",
    "        support = sum(n.count for n in tree.nodes(item))\n",
    "        if support < min_support:\n",
    "            # Doesn't make the cut anymore\n",
    "            for node in tree.nodes(item):\n",
    "                if node.parent is not None:\n",
    "                    node.parent.remove(node)\n",
    "\n",
    "    # Finally, remove the nodes corresponding to the item for which this\n",
    "    # conditional tree was generated.\n",
    "    for node in tree.nodes(condition_item):\n",
    "        if node.parent is not None: # the node might already be an orphan\n",
    "            node.parent.remove(node)\n",
    "\n",
    "    return tree\n",
    "\n",
    "class FPNode(object):\n",
    "    \"\"\"A node in an FP tree.\"\"\"\n",
    "\n",
    "    def __init__(self, tree, item, count=1):\n",
    "        self._tree = tree\n",
    "        self._item = item\n",
    "        self._count = count\n",
    "        self._parent = None\n",
    "        self._children = {}\n",
    "        self._neighbor = None\n",
    "\n",
    "    def add(self, child):\n",
    "        \"\"\"Adds the given FPNode `child` as a child of this node.\"\"\"\n",
    "\n",
    "        if not isinstance(child, FPNode):\n",
    "            raise TypeError(\"Can only add other FPNodes as children\")\n",
    "\n",
    "        if not child.item in self._children:\n",
    "            self._children[child.item] = child\n",
    "            child.parent = self\n",
    "\n",
    "    def search(self, item):\n",
    "        \"\"\"\n",
    "        Checks to see if this node contains a child node for the given item.\n",
    "        If so, that node is returned; otherwise, `None` is returned.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            return self._children[item]\n",
    "        except KeyError:\n",
    "            return None\n",
    "\n",
    "    def remove(self, child):\n",
    "        try:\n",
    "            if self._children[child.item] is child:\n",
    "                del self._children[child.item]\n",
    "                child.parent = None\n",
    "                self._tree._removed(child)\n",
    "                for sub_child in child.children:\n",
    "                    try:\n",
    "                        # Merger case: we already have a child for that item, so\n",
    "                        # add the sub-child's count to our child's count.\n",
    "                        self._children[sub_child.item]._count += sub_child.count\n",
    "                        sub_child.parent = None # it's an orphan now\n",
    "                    except KeyError:\n",
    "                        # Turns out we don't actually have a child, so just add\n",
    "                        # the sub-child as our own child.\n",
    "                        self.add(sub_child)\n",
    "                child._children = {}\n",
    "            else:\n",
    "                raise ValueError(\"that node is not a child of this node\")\n",
    "        except KeyError:\n",
    "            raise ValueError(\"that node is not a child of this node\")\n",
    "\n",
    "    def __contains__(self, item):\n",
    "        return item in self._children\n",
    "\n",
    "    @property\n",
    "    def tree(self):\n",
    "        \"\"\"The tree in which this node appears.\"\"\"\n",
    "        return self._tree\n",
    "\n",
    "    @property\n",
    "    def item(self):\n",
    "        \"\"\"The item contained in this node.\"\"\"\n",
    "        return self._item\n",
    "\n",
    "    @property\n",
    "    def count(self):\n",
    "        \"\"\"The count associated with this node's item.\"\"\"\n",
    "        return self._count\n",
    "\n",
    "    def increment(self):\n",
    "        \"\"\"Increments the count associated with this node's item.\"\"\"\n",
    "        if self._count is None:\n",
    "            raise ValueError(\"Root nodes have no associated count.\")\n",
    "        self._count += 1\n",
    "\n",
    "    @property\n",
    "    def root(self):\n",
    "        \"\"\"True if this node is the root of a tree; false if otherwise.\"\"\"\n",
    "        return self._item is None and self._count is None\n",
    "\n",
    "    @property\n",
    "    def leaf(self):\n",
    "        \"\"\"True if this node is a leaf in the tree; false if otherwise.\"\"\"\n",
    "        return len(self._children) == 0\n",
    "\n",
    "    def parent():\n",
    "        doc = \"The node's parent.\"\n",
    "        def fget(self):\n",
    "            return self._parent\n",
    "        def fset(self, value):\n",
    "            if value is not None and not isinstance(value, FPNode):\n",
    "                raise TypeError(\"A node must have an FPNode as a parent.\")\n",
    "            if value and value.tree is not self.tree:\n",
    "                raise ValueError(\"Cannot have a parent from another tree.\")\n",
    "            self._parent = value\n",
    "        return locals()\n",
    "    parent = property(**parent())\n",
    "\n",
    "    def neighbor():\n",
    "        doc = \"\"\"\n",
    "        The node's neighbor; the one with the same value that is \"to the right\"\n",
    "        of it in the tree.\n",
    "        \"\"\"\n",
    "        def fget(self):\n",
    "            return self._neighbor\n",
    "        def fset(self, value):\n",
    "            if value is not None and not isinstance(value, FPNode):\n",
    "                raise TypeError(\"A node must have an FPNode as a neighbor.\")\n",
    "            if value and value.tree is not self.tree:\n",
    "                raise ValueError(\"Cannot have a neighbor from another tree.\")\n",
    "            self._neighbor = value\n",
    "        return locals()\n",
    "    neighbor = property(**neighbor())\n",
    "\n",
    "    @property\n",
    "    def children(self):\n",
    "        \"\"\"The nodes that are children of this node.\"\"\"\n",
    "        #FIXME return tuple(self._children.itervalues())\n",
    "        return tuple(self._children.values())\n",
    "        \n",
    "    def inspect(self, depth=0):\n",
    "        print(('  ' * depth) + repr(self))\n",
    "        for child in self.children:\n",
    "            child.inspect(depth + 1)\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.root:\n",
    "            return \"<%s (root)>\" % type(self).__name__\n",
    "        return \"<%s %r (%r)>\" % (type(self).__name__, self.item, self.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apriori with a min support of 0.01:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ap_data_01 = apriori(D, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the rules found with a minconf of 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{yogurt, root vegetables} ---> {whole milk}:  conf = 0.563, sup = 0.015\n",
      "{curd, yogurt} ---> {whole milk}:  conf = 0.582, sup = 0.01\n",
      "{other vegetables, pip fruit} ---> {whole milk}:  conf = 0.518, sup = 0.014\n",
      "{other vegetables, whipped/sour cream} ---> {whole milk}:  conf = 0.507, sup = 0.015\n",
      "{other vegetables, butter} ---> {whole milk}:  conf = 0.574, sup = 0.011\n",
      "{yogurt, root vegetables} ---> {other vegetables}:  conf = 0.5, sup = 0.013\n",
      "{yogurt, whipped/sour cream} ---> {whole milk}:  conf = 0.525, sup = 0.011\n",
      "{rolls/buns, root vegetables} ---> {whole milk}:  conf = 0.523, sup = 0.013\n",
      "{other vegetables, yogurt} ---> {whole milk}:  conf = 0.513, sup = 0.022\n",
      "{citrus fruit, root vegetables} ---> {other vegetables}:  conf = 0.586, sup = 0.01\n",
      "{tropical fruit, root vegetables} ---> {other vegetables}:  conf = 0.585, sup = 0.012\n",
      "{domestic eggs, other vegetables} ---> {whole milk}:  conf = 0.553, sup = 0.012\n",
      "{tropical fruit, yogurt} ---> {whole milk}:  conf = 0.517, sup = 0.015\n",
      "{root vegetables, rolls/buns} ---> {other vegetables}:  conf = 0.502, sup = 0.012\n",
      "{tropical fruit, root vegetables} ---> {whole milk}:  conf = 0.57, sup = 0.012\n"
     ]
    }
   ],
   "source": [
    "ap_data_01_rules = generate_rules(ap_data_01[0], ap_data_01[1], min_confidence=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rules produced looks pretty good for a quick glance.  It may also be useful to try to find weaker association rules by reducing the support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ap_data_005 = apriori(D, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{baking powder} ---> {whole milk}:  conf = 0.523, sup = 0.009\n",
      "{newspapers, root vegetables} ---> {whole milk}:  conf = 0.504, sup = 0.006\n",
      "{curd, root vegetables} ---> {other vegetables}:  conf = 0.505, sup = 0.005\n",
      "{domestic eggs, margarine} ---> {whole milk}:  conf = 0.622, sup = 0.005\n",
      "{pork, root vegetables} ---> {whole milk}:  conf = 0.5, sup = 0.007\n",
      "{yogurt, pip fruit} ---> {whole milk}:  conf = 0.531, sup = 0.01\n",
      "{chicken, root vegetables} ---> {other vegetables}:  conf = 0.523, sup = 0.006\n",
      "{domestic eggs, root vegetables} ---> {other vegetables}:  conf = 0.511, sup = 0.007\n",
      "{pastry, tropical fruit} ---> {whole milk}:  conf = 0.508, sup = 0.007\n",
      "{tropical fruit, whipped/sour cream} ---> {whole milk}:  conf = 0.574, sup = 0.008\n",
      "{pastry, yogurt} ---> {whole milk}:  conf = 0.517, sup = 0.009\n",
      "{tropical fruit, sausage} ---> {whole milk}:  conf = 0.518, sup = 0.007\n",
      "{tropical fruit, root vegetables} ---> {other vegetables}:  conf = 0.585, sup = 0.012\n",
      "{tropical fruit, brown bread} ---> {whole milk}:  conf = 0.533, sup = 0.006\n",
      "{domestic eggs, other vegetables} ---> {whole milk}:  conf = 0.553, sup = 0.012\n",
      "{curd, whipped/sour cream} ---> {whole milk}:  conf = 0.563, sup = 0.006\n",
      "{frozen vegetables, root vegetables} ---> {whole milk}:  conf = 0.535, sup = 0.006\n",
      "{chicken, root vegetables} ---> {whole milk}:  conf = 0.551, sup = 0.006\n",
      "{yogurt, root vegetables} ---> {other vegetables}:  conf = 0.5, sup = 0.013\n",
      "{curd, rolls/buns} ---> {whole milk}:  conf = 0.586, sup = 0.006\n",
      "{rolls/buns, root vegetables} ---> {whole milk}:  conf = 0.523, sup = 0.013\n",
      "{newspapers, root vegetables} ---> {other vegetables}:  conf = 0.522, sup = 0.006\n",
      "{domestic eggs, root vegetables} ---> {whole milk}:  conf = 0.596, sup = 0.009\n",
      "{other vegetables, long life bakery product} ---> {whole milk}:  conf = 0.533, sup = 0.006\n",
      "{citrus fruit, root vegetables} ---> {other vegetables}:  conf = 0.586, sup = 0.01\n",
      "{frozen vegetables, root vegetables} ---> {other vegetables}:  conf = 0.526, sup = 0.006\n",
      "{whipped/sour cream, butter} ---> {whole milk}:  conf = 0.66, sup = 0.007\n",
      "{cream cheese , yogurt} ---> {whole milk}:  conf = 0.533, sup = 0.007\n",
      "{pip fruit, root vegetables} ---> {whole milk}:  conf = 0.575, sup = 0.009\n",
      "{whipped/sour cream, butter} ---> {other vegetables}:  conf = 0.57, sup = 0.006\n",
      "{frozen vegetables, rolls/buns} ---> {whole milk}:  conf = 0.5, sup = 0.005\n",
      "{domestic eggs, pip fruit} ---> {whole milk}:  conf = 0.624, sup = 0.005\n",
      "{whipped/sour cream, rolls/buns} ---> {whole milk}:  conf = 0.535, sup = 0.008\n",
      "{sausage, root vegetables} ---> {whole milk}:  conf = 0.517, sup = 0.008\n",
      "{pip fruit, whipped/sour cream} ---> {whole milk}:  conf = 0.648, sup = 0.006\n",
      "{other vegetables, hygiene articles} ---> {whole milk}:  conf = 0.543, sup = 0.005\n",
      "{yogurt, fruit/vegetable juice} ---> {whole milk}:  conf = 0.505, sup = 0.009\n",
      "{citrus fruit, root vegetables} ---> {whole milk}:  conf = 0.517, sup = 0.009\n",
      "{margarine, root vegetables} ---> {other vegetables}:  conf = 0.532, sup = 0.006\n",
      "{other vegetables, butter} ---> {whole milk}:  conf = 0.574, sup = 0.011\n",
      "{butter, root vegetables} ---> {whole milk}:  conf = 0.638, sup = 0.008\n",
      "{yogurt, coffee} ---> {whole milk}:  conf = 0.521, sup = 0.005\n",
      "{pip fruit, whipped/sour cream} ---> {other vegetables}:  conf = 0.604, sup = 0.006\n",
      "{pastry, root vegetables} ---> {whole milk}:  conf = 0.519, sup = 0.006\n",
      "{yogurt, whipped/sour cream} ---> {whole milk}:  conf = 0.525, sup = 0.011\n",
      "{yogurt, beef} ---> {whole milk}:  conf = 0.522, sup = 0.006\n",
      "{tropical fruit, whipped/sour cream} ---> {other vegetables}:  conf = 0.566, sup = 0.008\n",
      "{other vegetables, curd} ---> {whole milk}:  conf = 0.574, sup = 0.01\n",
      "{rolls/buns, root vegetables} ---> {other vegetables}:  conf = 0.502, sup = 0.012\n",
      "{brown bread, root vegetables} ---> {whole milk}:  conf = 0.56, sup = 0.006\n",
      "{other vegetables, frozen vegetables} ---> {whole milk}:  conf = 0.543, sup = 0.01\n",
      "{yogurt, root vegetables} ---> {whole milk}:  conf = 0.563, sup = 0.015\n",
      "{domestic eggs, citrus fruit} ---> {whole milk}:  conf = 0.549, sup = 0.006\n",
      "{other vegetables, oil} ---> {whole milk}:  conf = 0.51, sup = 0.005\n",
      "{frankfurter, tropical fruit} ---> {whole milk}:  conf = 0.548, sup = 0.005\n",
      "{shopping bags, root vegetables} ---> {other vegetables}:  conf = 0.516, sup = 0.007\n",
      "{domestic eggs, butter} ---> {whole milk}:  conf = 0.621, sup = 0.006\n",
      "{pork, rolls/buns} ---> {whole milk}:  conf = 0.55, sup = 0.006\n",
      "{sausage, whipped/sour cream} ---> {whole milk}:  conf = 0.562, sup = 0.005\n",
      "{beef, rolls/buns} ---> {whole milk}:  conf = 0.5, sup = 0.007\n",
      "{tropical fruit, curd} ---> {yogurt}:  conf = 0.515, sup = 0.005\n",
      "{pip fruit, root vegetables} ---> {other vegetables}:  conf = 0.523, sup = 0.008\n",
      "{pastry, root vegetables} ---> {other vegetables}:  conf = 0.537, sup = 0.006\n",
      "{other vegetables, yogurt} ---> {whole milk}:  conf = 0.513, sup = 0.022\n",
      "{chicken, rolls/buns} ---> {whole milk}:  conf = 0.547, sup = 0.005\n",
      "{yogurt, bottled beer} ---> {whole milk}:  conf = 0.56, sup = 0.005\n",
      "{onions, whole milk} ---> {other vegetables}:  conf = 0.546, sup = 0.007\n",
      "{butter, root vegetables} ---> {other vegetables}:  conf = 0.512, sup = 0.007\n",
      "{whipped/sour cream, root vegetables} ---> {whole milk}:  conf = 0.554, sup = 0.009\n",
      "{curd, yogurt} ---> {whole milk}:  conf = 0.582, sup = 0.01\n",
      "{other vegetables, whipped/sour cream} ---> {whole milk}:  conf = 0.507, sup = 0.015\n",
      "{domestic eggs, tropical fruit} ---> {whole milk}:  conf = 0.607, sup = 0.007\n",
      "{butter, bottled water} ---> {whole milk}:  conf = 0.602, sup = 0.005\n",
      "{domestic eggs, yogurt} ---> {whole milk}:  conf = 0.539, sup = 0.008\n",
      "{other vegetables, sugar} ---> {whole milk}:  conf = 0.585, sup = 0.006\n",
      "{citrus fruit, whipped/sour cream} ---> {other vegetables}:  conf = 0.523, sup = 0.006\n",
      "{citrus fruit, butter} ---> {whole milk}:  conf = 0.556, sup = 0.005\n",
      "{yogurt, butter} ---> {whole milk}:  conf = 0.639, sup = 0.009\n",
      "{tropical fruit, butter} ---> {whole milk}:  conf = 0.622, sup = 0.006\n",
      "{pork, root vegetables} ---> {other vegetables}:  conf = 0.515, sup = 0.007\n",
      "{domestic eggs, whipped/sour cream} ---> {other vegetables}:  conf = 0.51, sup = 0.005\n",
      "{pip fruit, sausage} ---> {whole milk}:  conf = 0.519, sup = 0.006\n",
      "{margarine, rolls/buns} ---> {whole milk}:  conf = 0.538, sup = 0.008\n",
      "{fruit/vegetable juice, root vegetables} ---> {whole milk}:  conf = 0.542, sup = 0.007\n",
      "{frankfurter, yogurt} ---> {whole milk}:  conf = 0.555, sup = 0.006\n",
      "{fruit/vegetable juice, root vegetables} ---> {other vegetables}:  conf = 0.551, sup = 0.007\n",
      "{other vegetables, pip fruit} ---> {whole milk}:  conf = 0.518, sup = 0.014\n",
      "{frankfurter, root vegetables} ---> {whole milk}:  conf = 0.5, sup = 0.005\n",
      "{onions, root vegetables} ---> {other vegetables}:  conf = 0.602, sup = 0.006\n",
      "{citrus fruit, whipped/sour cream} ---> {whole milk}:  conf = 0.579, sup = 0.006\n",
      "{tropical fruit, curd} ---> {other vegetables}:  conf = 0.515, sup = 0.005\n",
      "{other vegetables, brown bread} ---> {whole milk}:  conf = 0.5, sup = 0.009\n",
      "{domestic eggs, whipped/sour cream} ---> {whole milk}:  conf = 0.571, sup = 0.006\n",
      "{curd, root vegetables} ---> {whole milk}:  conf = 0.57, sup = 0.006\n",
      "{tropical fruit, butter} ---> {other vegetables}:  conf = 0.551, sup = 0.005\n",
      "{tropical fruit, curd} ---> {whole milk}:  conf = 0.634, sup = 0.007\n",
      "{whipped/sour cream, root vegetables} ---> {other vegetables}:  conf = 0.5, sup = 0.009\n",
      "{tropical fruit, yogurt} ---> {whole milk}:  conf = 0.517, sup = 0.015\n",
      "{tropical fruit, root vegetables} ---> {whole milk}:  conf = 0.57, sup = 0.012\n",
      "{yogurt, whole milk, root vegetables} ---> {other vegetables}:  conf = 0.538, sup = 0.008\n",
      "{other vegetables, yogurt, root vegetables} ---> {whole milk}:  conf = 0.606, sup = 0.008\n",
      "{tropical fruit, yogurt, whole milk} ---> {other vegetables}:  conf = 0.503, sup = 0.008\n",
      "{other vegetables, tropical fruit, yogurt} ---> {whole milk}:  conf = 0.62, sup = 0.008\n",
      "{tropical fruit, whole milk, root vegetables} ---> {other vegetables}:  conf = 0.585, sup = 0.007\n",
      "{other vegetables, tropical fruit, root vegetables} ---> {whole milk}:  conf = 0.57, sup = 0.007\n",
      "{pip fruit, whole milk, root vegetables} ---> {other vegetables}:  conf = 0.614, sup = 0.005\n",
      "{other vegetables, pip fruit, root vegetables} ---> {whole milk}:  conf = 0.675, sup = 0.005\n",
      "{yogurt, pip fruit, whole milk} ---> {other vegetables}:  conf = 0.532, sup = 0.005\n",
      "{other vegetables, yogurt, pip fruit} ---> {whole milk}:  conf = 0.625, sup = 0.005\n",
      "{yogurt, fruit/vegetable juice, whole milk} ---> {other vegetables}:  conf = 0.538, sup = 0.005\n",
      "{other vegetables, yogurt, fruit/vegetable juice} ---> {whole milk}:  conf = 0.617, sup = 0.005\n",
      "{whipped/sour cream, whole milk, root vegetables} ---> {other vegetables}:  conf = 0.548, sup = 0.005\n",
      "{other vegetables, whipped/sour cream, root vegetables} ---> {whole milk}:  conf = 0.607, sup = 0.005\n",
      "{yogurt, whipped/sour cream, whole milk} ---> {other vegetables}:  conf = 0.514, sup = 0.006\n",
      "{other vegetables, yogurt, whipped/sour cream} ---> {whole milk}:  conf = 0.55, sup = 0.006\n",
      "{other vegetables, yogurt, rolls/buns} ---> {whole milk}:  conf = 0.522, sup = 0.006\n",
      "{rolls/buns, other vegetables, root vegetables} ---> {whole milk}:  conf = 0.508, sup = 0.006\n",
      "{citrus fruit, whole milk, root vegetables} ---> {other vegetables}:  conf = 0.633, sup = 0.006\n",
      "{other vegetables, citrus fruit, root vegetables} ---> {whole milk}:  conf = 0.559, sup = 0.006\n",
      "{tropical fruit, yogurt, root vegetables} ---> {whole milk}:  conf = 0.7, sup = 0.006\n"
     ]
    }
   ],
   "source": [
    "ap_data_005_rules = generate_rules(ap_data_005[0], ap_data_005[1], min_confidence=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also produce a list of higher confidence rules (minconf = 0.6) using the same low minsup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{domestic eggs, margarine} ---> {whole milk}:  conf = 0.622, sup = 0.005\n",
      "{whipped/sour cream, butter} ---> {whole milk}:  conf = 0.66, sup = 0.007\n",
      "{domestic eggs, pip fruit} ---> {whole milk}:  conf = 0.624, sup = 0.005\n",
      "{pip fruit, whipped/sour cream} ---> {whole milk}:  conf = 0.648, sup = 0.006\n",
      "{butter, root vegetables} ---> {whole milk}:  conf = 0.638, sup = 0.008\n",
      "{pip fruit, whipped/sour cream} ---> {other vegetables}:  conf = 0.604, sup = 0.006\n",
      "{domestic eggs, butter} ---> {whole milk}:  conf = 0.621, sup = 0.006\n",
      "{domestic eggs, tropical fruit} ---> {whole milk}:  conf = 0.607, sup = 0.007\n",
      "{butter, bottled water} ---> {whole milk}:  conf = 0.602, sup = 0.005\n",
      "{yogurt, butter} ---> {whole milk}:  conf = 0.639, sup = 0.009\n",
      "{tropical fruit, butter} ---> {whole milk}:  conf = 0.622, sup = 0.006\n",
      "{onions, root vegetables} ---> {other vegetables}:  conf = 0.602, sup = 0.006\n",
      "{tropical fruit, curd} ---> {whole milk}:  conf = 0.634, sup = 0.007\n",
      "{other vegetables, yogurt, root vegetables} ---> {whole milk}:  conf = 0.606, sup = 0.008\n",
      "{other vegetables, tropical fruit, yogurt} ---> {whole milk}:  conf = 0.62, sup = 0.008\n",
      "{pip fruit, whole milk, root vegetables} ---> {other vegetables}:  conf = 0.614, sup = 0.005\n",
      "{other vegetables, pip fruit, root vegetables} ---> {whole milk}:  conf = 0.675, sup = 0.005\n",
      "{other vegetables, yogurt, pip fruit} ---> {whole milk}:  conf = 0.625, sup = 0.005\n",
      "{other vegetables, yogurt, fruit/vegetable juice} ---> {whole milk}:  conf = 0.617, sup = 0.005\n",
      "{other vegetables, whipped/sour cream, root vegetables} ---> {whole milk}:  conf = 0.607, sup = 0.005\n",
      "{citrus fruit, whole milk, root vegetables} ---> {other vegetables}:  conf = 0.633, sup = 0.006\n",
      "{tropical fruit, yogurt, root vegetables} ---> {whole milk}:  conf = 0.7, sup = 0.006\n"
     ]
    }
   ],
   "source": [
    "ap_data_005_rules_60 = generate_rules(ap_data_005[0], ap_data_005[1], min_confidence=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From both smaller sets of rules we see that whole milk is very commonly bought with other sets of goods such as butter & yogurt or root vegetables & butter.  Likewise, root vegetables are also often bought with milk (or occasionally with other vegetables) if other goods are bought along with it such as pip fruit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the lift to consider how usable these rules are on future data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given a set of rules and support values, calcuates the lift.\n",
    "def lift(rule, support):\n",
    "    set_union = rule[0].union(rule[1])\n",
    "    # Lift calculation: supp(X U Y) / (supp(X) x supp(Y))\n",
    "    return support[set_union]/(support[rule[0]]*support[rule[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2994413015268096"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minsup = 0.01, minconf = 0.5\n",
    "np.mean([lift(x, ap_data_01[1]) for x in ap_data_01_rules])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3789974157626252"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minsup = 0.005, minconf = 0.5\n",
    "np.mean([lift(x, ap_data_005[1]) for x in ap_data_005_rules])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5985988229807431"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minsup = 0.005, minconf = 0.6\n",
    "np.mean([lift(x, ap_data_005[1]) for x in ap_data_005_rules_60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that a minsup of 0.005 and a minconf of 0.6 provides the best overall lift across the generated rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do the same thresholds with FPGrowth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp_data_01 = fpgrowth(D, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{yogurt, whipped/sour cream} ---> {whole milk}:  conf = 0.525, sup = 0.011\n",
      "{other vegetables, whipped/sour cream} ---> {whole milk}:  conf = 0.507, sup = 0.015\n",
      "{other vegetables, pip fruit} ---> {whole milk}:  conf = 0.518, sup = 0.014\n",
      "{curd, yogurt} ---> {whole milk}:  conf = 0.582, sup = 0.01\n",
      "{tropical fruit, yogurt} ---> {whole milk}:  conf = 0.517, sup = 0.015\n",
      "{tropical fruit, root vegetables} ---> {other vegetables}:  conf = 0.585, sup = 0.012\n",
      "{tropical fruit, root vegetables} ---> {whole milk}:  conf = 0.57, sup = 0.012\n",
      "{citrus fruit, root vegetables} ---> {other vegetables}:  conf = 0.586, sup = 0.01\n",
      "{yogurt, root vegetables} ---> {other vegetables}:  conf = 0.5, sup = 0.013\n",
      "{yogurt, root vegetables} ---> {whole milk}:  conf = 0.563, sup = 0.015\n",
      "{rolls/buns, root vegetables} ---> {other vegetables}:  conf = 0.502, sup = 0.012\n",
      "{rolls/buns, root vegetables} ---> {whole milk}:  conf = 0.523, sup = 0.013\n",
      "{other vegetables, butter} ---> {whole milk}:  conf = 0.574, sup = 0.011\n",
      "{other vegetables, yogurt} ---> {whole milk}:  conf = 0.513, sup = 0.022\n",
      "{domestic eggs, other vegetables} ---> {whole milk}:  conf = 0.553, sup = 0.012\n"
     ]
    }
   ],
   "source": [
    "fp_data_01_rules = generate_rules(fp_data_01[0], fp_data_01[1], min_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp_data_005 = fpgrowth(D, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{baking powder} ---> {whole milk}:  conf = 0.523, sup = 0.009\n",
      "{tropical fruit, sausage} ---> {whole milk}:  conf = 0.518, sup = 0.007\n",
      "{sausage, root vegetables} ---> {whole milk}:  conf = 0.517, sup = 0.008\n",
      "{other vegetables, hygiene articles} ---> {whole milk}:  conf = 0.543, sup = 0.005\n",
      "{yogurt, whipped/sour cream} ---> {whole milk}:  conf = 0.525, sup = 0.011\n",
      "{sausage, whipped/sour cream} ---> {whole milk}:  conf = 0.562, sup = 0.005\n",
      "{pip fruit, whipped/sour cream} ---> {other vegetables}:  conf = 0.604, sup = 0.006\n",
      "{pip fruit, whipped/sour cream} ---> {whole milk}:  conf = 0.648, sup = 0.006\n",
      "{whipped/sour cream, root vegetables} ---> {other vegetables}:  conf = 0.5, sup = 0.009\n",
      "{whipped/sour cream, root vegetables} ---> {whole milk}:  conf = 0.554, sup = 0.009\n",
      "{other vegetables, whipped/sour cream} ---> {whole milk}:  conf = 0.507, sup = 0.015\n",
      "{whipped/sour cream, rolls/buns} ---> {whole milk}:  conf = 0.535, sup = 0.008\n",
      "{citrus fruit, whipped/sour cream} ---> {other vegetables}:  conf = 0.523, sup = 0.006\n",
      "{citrus fruit, whipped/sour cream} ---> {whole milk}:  conf = 0.579, sup = 0.006\n",
      "{tropical fruit, whipped/sour cream} ---> {other vegetables}:  conf = 0.566, sup = 0.008\n",
      "{tropical fruit, whipped/sour cream} ---> {whole milk}:  conf = 0.574, sup = 0.008\n",
      "{other vegetables, oil} ---> {whole milk}:  conf = 0.51, sup = 0.005\n",
      "{other vegetables, sugar} ---> {whole milk}:  conf = 0.585, sup = 0.006\n",
      "{frozen vegetables, root vegetables} ---> {other vegetables}:  conf = 0.526, sup = 0.006\n",
      "{frozen vegetables, root vegetables} ---> {whole milk}:  conf = 0.535, sup = 0.006\n",
      "{other vegetables, frozen vegetables} ---> {whole milk}:  conf = 0.543, sup = 0.01\n",
      "{frozen vegetables, rolls/buns} ---> {whole milk}:  conf = 0.5, sup = 0.005\n",
      "{yogurt, pip fruit} ---> {whole milk}:  conf = 0.531, sup = 0.01\n",
      "{sausage, pip fruit} ---> {whole milk}:  conf = 0.519, sup = 0.006\n",
      "{pip fruit, root vegetables} ---> {other vegetables}:  conf = 0.523, sup = 0.008\n",
      "{pip fruit, root vegetables} ---> {whole milk}:  conf = 0.575, sup = 0.009\n",
      "{other vegetables, pip fruit} ---> {whole milk}:  conf = 0.518, sup = 0.014\n",
      "{curd, root vegetables} ---> {other vegetables}:  conf = 0.505, sup = 0.005\n",
      "{curd, root vegetables} ---> {whole milk}:  conf = 0.57, sup = 0.006\n",
      "{other vegetables, curd} ---> {whole milk}:  conf = 0.574, sup = 0.01\n",
      "{curd, yogurt} ---> {whole milk}:  conf = 0.582, sup = 0.01\n",
      "{curd, whipped/sour cream} ---> {whole milk}:  conf = 0.563, sup = 0.006\n",
      "{tropical fruit, curd} ---> {yogurt}:  conf = 0.515, sup = 0.005\n",
      "{tropical fruit, curd} ---> {other vegetables}:  conf = 0.515, sup = 0.005\n",
      "{tropical fruit, curd} ---> {whole milk}:  conf = 0.634, sup = 0.007\n",
      "{curd, rolls/buns} ---> {whole milk}:  conf = 0.586, sup = 0.006\n",
      "{yogurt, beef} ---> {whole milk}:  conf = 0.522, sup = 0.006\n",
      "{beef, rolls/buns} ---> {whole milk}:  conf = 0.5, sup = 0.007\n",
      "{other vegetables, long life bakery product} ---> {whole milk}:  conf = 0.533, sup = 0.006\n",
      "{shopping bags, root vegetables} ---> {other vegetables}:  conf = 0.516, sup = 0.007\n",
      "{tropical fruit, yogurt} ---> {whole milk}:  conf = 0.517, sup = 0.015\n",
      "{tropical fruit, root vegetables} ---> {other vegetables}:  conf = 0.585, sup = 0.012\n",
      "{tropical fruit, root vegetables} ---> {whole milk}:  conf = 0.57, sup = 0.012\n",
      "{citrus fruit, root vegetables} ---> {other vegetables}:  conf = 0.586, sup = 0.01\n",
      "{citrus fruit, root vegetables} ---> {whole milk}:  conf = 0.517, sup = 0.009\n",
      "{newspapers, root vegetables} ---> {other vegetables}:  conf = 0.522, sup = 0.006\n",
      "{newspapers, root vegetables} ---> {whole milk}:  conf = 0.504, sup = 0.006\n",
      "{yogurt, root vegetables} ---> {other vegetables}:  conf = 0.5, sup = 0.013\n",
      "{yogurt, root vegetables} ---> {whole milk}:  conf = 0.563, sup = 0.015\n",
      "{rolls/buns, root vegetables} ---> {other vegetables}:  conf = 0.502, sup = 0.012\n",
      "{rolls/buns, root vegetables} ---> {whole milk}:  conf = 0.523, sup = 0.013\n",
      "{butter, root vegetables} ---> {other vegetables}:  conf = 0.512, sup = 0.007\n",
      "{butter, root vegetables} ---> {whole milk}:  conf = 0.638, sup = 0.008\n",
      "{other vegetables, butter} ---> {whole milk}:  conf = 0.574, sup = 0.011\n",
      "{domestic eggs, butter} ---> {whole milk}:  conf = 0.621, sup = 0.006\n",
      "{butter, bottled water} ---> {whole milk}:  conf = 0.602, sup = 0.005\n",
      "{whipped/sour cream, butter} ---> {other vegetables}:  conf = 0.57, sup = 0.006\n",
      "{whipped/sour cream, butter} ---> {whole milk}:  conf = 0.66, sup = 0.007\n",
      "{yogurt, butter} ---> {whole milk}:  conf = 0.639, sup = 0.009\n",
      "{tropical fruit, butter} ---> {other vegetables}:  conf = 0.551, sup = 0.005\n",
      "{tropical fruit, butter} ---> {whole milk}:  conf = 0.622, sup = 0.006\n",
      "{citrus fruit, butter} ---> {whole milk}:  conf = 0.556, sup = 0.005\n",
      "{pork, root vegetables} ---> {other vegetables}:  conf = 0.515, sup = 0.007\n",
      "{pork, root vegetables} ---> {whole milk}:  conf = 0.5, sup = 0.007\n",
      "{pork, rolls/buns} ---> {whole milk}:  conf = 0.55, sup = 0.006\n",
      "{margarine, root vegetables} ---> {other vegetables}:  conf = 0.532, sup = 0.006\n",
      "{domestic eggs, margarine} ---> {whole milk}:  conf = 0.622, sup = 0.005\n",
      "{margarine, rolls/buns} ---> {whole milk}:  conf = 0.538, sup = 0.008\n",
      "{yogurt, fruit/vegetable juice} ---> {whole milk}:  conf = 0.505, sup = 0.009\n",
      "{fruit/vegetable juice, root vegetables} ---> {other vegetables}:  conf = 0.551, sup = 0.007\n",
      "{fruit/vegetable juice, root vegetables} ---> {whole milk}:  conf = 0.542, sup = 0.007\n",
      "{yogurt, coffee} ---> {whole milk}:  conf = 0.521, sup = 0.005\n",
      "{pastry, yogurt} ---> {whole milk}:  conf = 0.517, sup = 0.009\n",
      "{pastry, root vegetables} ---> {other vegetables}:  conf = 0.537, sup = 0.006\n",
      "{pastry, root vegetables} ---> {whole milk}:  conf = 0.519, sup = 0.006\n",
      "{pastry, tropical fruit} ---> {whole milk}:  conf = 0.508, sup = 0.007\n",
      "{other vegetables, yogurt} ---> {whole milk}:  conf = 0.513, sup = 0.022\n",
      "{frankfurter, yogurt} ---> {whole milk}:  conf = 0.555, sup = 0.006\n",
      "{frankfurter, root vegetables} ---> {whole milk}:  conf = 0.5, sup = 0.005\n",
      "{frankfurter, tropical fruit} ---> {whole milk}:  conf = 0.548, sup = 0.005\n",
      "{onions, root vegetables} ---> {other vegetables}:  conf = 0.602, sup = 0.006\n",
      "{whole milk, onions} ---> {other vegetables}:  conf = 0.546, sup = 0.007\n",
      "{domestic eggs, yogurt} ---> {whole milk}:  conf = 0.539, sup = 0.008\n",
      "{domestic eggs, whipped/sour cream} ---> {other vegetables}:  conf = 0.51, sup = 0.005\n",
      "{domestic eggs, whipped/sour cream} ---> {whole milk}:  conf = 0.571, sup = 0.006\n",
      "{domestic eggs, root vegetables} ---> {other vegetables}:  conf = 0.511, sup = 0.007\n",
      "{domestic eggs, root vegetables} ---> {whole milk}:  conf = 0.596, sup = 0.009\n",
      "{domestic eggs, other vegetables} ---> {whole milk}:  conf = 0.553, sup = 0.012\n",
      "{domestic eggs, citrus fruit} ---> {whole milk}:  conf = 0.549, sup = 0.006\n",
      "{domestic eggs, tropical fruit} ---> {whole milk}:  conf = 0.607, sup = 0.007\n",
      "{domestic eggs, pip fruit} ---> {whole milk}:  conf = 0.624, sup = 0.005\n",
      "{chicken, root vegetables} ---> {other vegetables}:  conf = 0.523, sup = 0.006\n",
      "{chicken, root vegetables} ---> {whole milk}:  conf = 0.551, sup = 0.006\n",
      "{chicken, rolls/buns} ---> {whole milk}:  conf = 0.547, sup = 0.005\n",
      "{brown bread, root vegetables} ---> {whole milk}:  conf = 0.56, sup = 0.006\n",
      "{other vegetables, brown bread} ---> {whole milk}:  conf = 0.5, sup = 0.009\n",
      "{tropical fruit, brown bread} ---> {whole milk}:  conf = 0.533, sup = 0.006\n",
      "{yogurt, bottled beer} ---> {whole milk}:  conf = 0.56, sup = 0.005\n",
      "{cream cheese , yogurt} ---> {whole milk}:  conf = 0.533, sup = 0.007\n",
      "{yogurt, whipped/sour cream, whole milk} ---> {other vegetables}:  conf = 0.514, sup = 0.006\n",
      "{other vegetables, yogurt, whipped/sour cream} ---> {whole milk}:  conf = 0.55, sup = 0.006\n",
      "{whipped/sour cream, whole milk, root vegetables} ---> {other vegetables}:  conf = 0.548, sup = 0.005\n",
      "{other vegetables, whipped/sour cream, root vegetables} ---> {whole milk}:  conf = 0.607, sup = 0.005\n",
      "{yogurt, pip fruit, whole milk} ---> {other vegetables}:  conf = 0.532, sup = 0.005\n",
      "{other vegetables, yogurt, pip fruit} ---> {whole milk}:  conf = 0.625, sup = 0.005\n",
      "{pip fruit, whole milk, root vegetables} ---> {other vegetables}:  conf = 0.614, sup = 0.005\n",
      "{other vegetables, pip fruit, root vegetables} ---> {whole milk}:  conf = 0.675, sup = 0.005\n",
      "{tropical fruit, yogurt, whole milk} ---> {other vegetables}:  conf = 0.503, sup = 0.008\n",
      "{other vegetables, tropical fruit, yogurt} ---> {whole milk}:  conf = 0.62, sup = 0.008\n",
      "{tropical fruit, yogurt, root vegetables} ---> {whole milk}:  conf = 0.7, sup = 0.006\n",
      "{tropical fruit, whole milk, root vegetables} ---> {other vegetables}:  conf = 0.585, sup = 0.007\n",
      "{other vegetables, tropical fruit, root vegetables} ---> {whole milk}:  conf = 0.57, sup = 0.007\n",
      "{citrus fruit, whole milk, root vegetables} ---> {other vegetables}:  conf = 0.633, sup = 0.006\n",
      "{other vegetables, citrus fruit, root vegetables} ---> {whole milk}:  conf = 0.559, sup = 0.006\n",
      "{yogurt, whole milk, root vegetables} ---> {other vegetables}:  conf = 0.538, sup = 0.008\n",
      "{other vegetables, yogurt, root vegetables} ---> {whole milk}:  conf = 0.606, sup = 0.008\n",
      "{rolls/buns, other vegetables, root vegetables} ---> {whole milk}:  conf = 0.508, sup = 0.006\n",
      "{yogurt, fruit/vegetable juice, whole milk} ---> {other vegetables}:  conf = 0.538, sup = 0.005\n",
      "{other vegetables, yogurt, fruit/vegetable juice} ---> {whole milk}:  conf = 0.617, sup = 0.005\n",
      "{other vegetables, yogurt, rolls/buns} ---> {whole milk}:  conf = 0.522, sup = 0.006\n"
     ]
    }
   ],
   "source": [
    "fp_data_005_rules = generate_rules(fp_data_005[0], fp_data_005[1], min_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{pip fruit, whipped/sour cream} ---> {other vegetables}:  conf = 0.604, sup = 0.006\n",
      "{pip fruit, whipped/sour cream} ---> {whole milk}:  conf = 0.648, sup = 0.006\n",
      "{tropical fruit, curd} ---> {whole milk}:  conf = 0.634, sup = 0.007\n",
      "{butter, root vegetables} ---> {whole milk}:  conf = 0.638, sup = 0.008\n",
      "{domestic eggs, butter} ---> {whole milk}:  conf = 0.621, sup = 0.006\n",
      "{butter, bottled water} ---> {whole milk}:  conf = 0.602, sup = 0.005\n",
      "{whipped/sour cream, butter} ---> {whole milk}:  conf = 0.66, sup = 0.007\n",
      "{yogurt, butter} ---> {whole milk}:  conf = 0.639, sup = 0.009\n",
      "{tropical fruit, butter} ---> {whole milk}:  conf = 0.622, sup = 0.006\n",
      "{domestic eggs, margarine} ---> {whole milk}:  conf = 0.622, sup = 0.005\n",
      "{onions, root vegetables} ---> {other vegetables}:  conf = 0.602, sup = 0.006\n",
      "{domestic eggs, tropical fruit} ---> {whole milk}:  conf = 0.607, sup = 0.007\n",
      "{domestic eggs, pip fruit} ---> {whole milk}:  conf = 0.624, sup = 0.005\n",
      "{other vegetables, whipped/sour cream, root vegetables} ---> {whole milk}:  conf = 0.607, sup = 0.005\n",
      "{other vegetables, yogurt, pip fruit} ---> {whole milk}:  conf = 0.625, sup = 0.005\n",
      "{pip fruit, whole milk, root vegetables} ---> {other vegetables}:  conf = 0.614, sup = 0.005\n",
      "{other vegetables, pip fruit, root vegetables} ---> {whole milk}:  conf = 0.675, sup = 0.005\n",
      "{other vegetables, tropical fruit, yogurt} ---> {whole milk}:  conf = 0.62, sup = 0.008\n",
      "{tropical fruit, yogurt, root vegetables} ---> {whole milk}:  conf = 0.7, sup = 0.006\n",
      "{citrus fruit, whole milk, root vegetables} ---> {other vegetables}:  conf = 0.633, sup = 0.006\n",
      "{other vegetables, yogurt, root vegetables} ---> {whole milk}:  conf = 0.606, sup = 0.008\n",
      "{other vegetables, yogurt, fruit/vegetable juice} ---> {whole milk}:  conf = 0.617, sup = 0.005\n"
     ]
    }
   ],
   "source": [
    "fp_data_005_rules_60 = generate_rules(fp_data_005[0], fp_data_005[1], min_confidence=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rules produced by FPGrowth are the same, just in a different order.  FPGrowth is a little faster as well.\n",
    "\n",
    "The tests below show that the results are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Returns True if both sets have all the same values\n",
    "def same_sets(set1, set2):\n",
    "    return not bool(set(set1).difference(set2))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minsup = 0.01, minconf = 0.5\n",
    "same_sets(ap_data_01_rules, fp_data_01_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minsup = 0.005, minconf = 0.5\n",
    "same_sets(ap_data_005_rules, fp_data_005_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minsup = 0.005, minconf = 0.6\n",
    "same_sets(ap_data_005_rules_60, fp_data_005_rules_60)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
